{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3810d3-a909-45b3-acc7-1f4faea4f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q1.\n",
    "\n",
    "Batch normalization is a technique used in Artificial Neural Networks (ANNs) to improve the training process and overall performance of the network. It aims to address the issue of internal covariate shift, which refers to the change in the distribution of layer inputs during training. By normalizing the inputs within each mini-batch, batch normalization helps stabilize and speed up the training process.\n",
    "\n",
    "The benefits of using batch normalization during training include:\n",
    "\n",
    "Reduced internal covariate shift: Batch normalization ensures that the mean activation of each layer remains close to zero, and the standard deviation is close to one. This helps in reducing the internal covariate shift, which in turn leads to faster and more stable convergence during training.\n",
    "\n",
    "Improved gradient flow: Batch normalization normalizes the inputs for each mini-batch, which helps in reducing the dependence of gradients on the scale of the parameters or the initial learning rate. This improves the flow of gradients through the network, allowing for better and more efficient training.\n",
    "\n",
    "Regularization effect: Batch normalization introduces a slight regularization effect by adding noise to the network during training. This noise acts as a regularizer and helps in reducing overfitting, allowing the network to generalize better to unseen data.\n",
    "\n",
    "Better handling of different scales and distributions: Batch normalization normalizes the inputs within each mini-batch, making the network less sensitive to the scale and distribution of the input data. This enables the network to handle inputs with different scales and distributions more effectively.\n",
    "\n",
    "The working principle of batch normalization involves two main steps: normalization and learnable parameters.\n",
    "\n",
    "Normalization step: In this step, the inputs to a layer are normalized to have zero mean and unit variance. For each mini-batch during training, the mean and variance of the inputs are computed. Then, the inputs are subtracted by the mean and divided by the square root of the variance. This normalization step ensures that the inputs to the subsequent layer have similar distributions, regardless of the scale and distribution of the inputs.\n",
    "\n",
    "Learnable parameters: In addition to the normalization step, batch normalization introduces learnable parameters to the network. These parameters include a scale parameter (gamma) and a shift parameter (beta). These parameters allow the network to learn the optimal scale and shift for the normalized inputs. The scale parameter scales the normalized inputs, and the shift parameter adds a bias term. These parameters are learned during the training process using backpropagation.\n",
    "\n",
    "During inference (testing or prediction phase), the learned mean and variance for each batch are used to normalize the inputs, ensuring consistency with the training process.\n",
    "\n",
    "Overall, batch normalization helps in addressing the internal covariate shift, improves gradient flow, adds regularization, and enhances the network's ability to handle inputs with different scales and distributions, resulting in more efficient and effective training of artificial neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a734c1c-08ce-4f60-9271-5014034aae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q2.\n",
    "\n",
    "\n",
    "To demonstrate the impact of batch normalization, let's consider the MNIST dataset, which consists of grayscale images of handwritten digits. We'll implement a simple feedforward neural network using the PyTorch deep learning framework.\n",
    "\n",
    "First, we need to preprocess the dataset by normalizing the pixel values and splitting it into training and validation sets:\n",
    "    \n",
    "    \n",
    " import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Loading MNIST dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Splitting into training and validation sets\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "Now, we can implement the feedforward neural network without using batch normalization:\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea31da-db0c-4fef-ab3e-695a384dcd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e846560-3aee-4227-a332-355fbdd49c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42343aab-26c2-4798-940e-8c033d0b9585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
